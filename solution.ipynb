{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6324b330-9daa-495f-a4a5-17989f4839f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0f56dfb0-aba5-42e4-83ed-e7f8d225c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PL</th>\n",
       "      <th>VaRBHS</th>\n",
       "      <th>VaREWMA</th>\n",
       "      <th>VaRn</th>\n",
       "      <th>VaRt</th>\n",
       "      <th>VaRPot</th>\n",
       "      <th>ESEWMA</th>\n",
       "      <th>ESn</th>\n",
       "      <th>ESt</th>\n",
       "      <th>ESPot</th>\n",
       "      <th>Losses</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-12-26</td>\n",
       "      <td>-150</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1147.464693</td>\n",
       "      <td>777.535296</td>\n",
       "      <td>986.872911</td>\n",
       "      <td>1391.726372</td>\n",
       "      <td>2544.116901</td>\n",
       "      <td>897.215494</td>\n",
       "      <td>3209.017239</td>\n",
       "      <td>1924.333523</td>\n",
       "      <td>150</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-12-28</td>\n",
       "      <td>150</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1144.195603</td>\n",
       "      <td>778.321836</td>\n",
       "      <td>987.104816</td>\n",
       "      <td>1391.726372</td>\n",
       "      <td>2540.137912</td>\n",
       "      <td>898.017553</td>\n",
       "      <td>3189.914672</td>\n",
       "      <td>1924.333523</td>\n",
       "      <td>-150</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-29</td>\n",
       "      <td>-20</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1117.460475</td>\n",
       "      <td>778.334975</td>\n",
       "      <td>987.885905</td>\n",
       "      <td>1391.726372</td>\n",
       "      <td>2506.631070</td>\n",
       "      <td>898.020953</td>\n",
       "      <td>3203.255498</td>\n",
       "      <td>1924.333523</td>\n",
       "      <td>20</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-12-31</td>\n",
       "      <td>30</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1085.901247</td>\n",
       "      <td>777.503184</td>\n",
       "      <td>989.976454</td>\n",
       "      <td>1391.726372</td>\n",
       "      <td>2468.406961</td>\n",
       "      <td>897.126264</td>\n",
       "      <td>3261.771712</td>\n",
       "      <td>1924.333523</td>\n",
       "      <td>-30</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>30</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>1053.756229</td>\n",
       "      <td>777.645897</td>\n",
       "      <td>990.797723</td>\n",
       "      <td>1391.726372</td>\n",
       "      <td>2431.278879</td>\n",
       "      <td>897.263546</td>\n",
       "      <td>3270.873551</td>\n",
       "      <td>1924.333523</td>\n",
       "      <td>-30</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   PL  VaRBHS      VaREWMA        VaRn        VaRt       VaRPot  \\\n",
       "0 2006-12-26 -150  1115.0  1147.464693  777.535296  986.872911  1391.726372   \n",
       "1 2006-12-28  150  1115.0  1144.195603  778.321836  987.104816  1391.726372   \n",
       "2 2006-12-29  -20  1115.0  1117.460475  778.334975  987.885905  1391.726372   \n",
       "3 2006-12-31   30  1115.0  1085.901247  777.503184  989.976454  1391.726372   \n",
       "4 2007-01-01   30  1115.0  1053.756229  777.645897  990.797723  1391.726372   \n",
       "\n",
       "        ESEWMA         ESn          ESt        ESPot  Losses  Year  \n",
       "0  2544.116901  897.215494  3209.017239  1924.333523     150  2006  \n",
       "1  2540.137912  898.017553  3189.914672  1924.333523    -150  2006  \n",
       "2  2506.631070  898.020953  3203.255498  1924.333523      20  2006  \n",
       "3  2468.406961  897.126264  3261.771712  1924.333523     -30  2006  \n",
       "4  2431.278879  897.263546  3270.873551  1924.333523     -30  2007  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "file_path = \"DataLab2.xlsx\" \n",
    "\n",
    "# Read the first 501 to 1009 rows and first 11 columns\n",
    "df = pd.read_excel(file_path, header=0, skiprows=range(1, 501), usecols=range(11))\n",
    "\n",
    "# Transform 'PL' column to create 'Losses' column\n",
    "df[\"Losses\"] = df[\"PL\"] * (-1)\n",
    "\n",
    "# extract the years\n",
    "df[\"Year\"] = df[\"Date\"].dt.year.astype(int)\n",
    "\n",
    "# Display the first few rows (for testing)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4fcd18e4-e2bf-4ff4-be15-91f0e32a809b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Backtesting VAR\n",
    "\n",
    "# encode exceptions for each VAR\n",
    "var_indices = list(range(2,7)) # these are the columns indices for the VAR\n",
    "\n",
    "# to get all the names of the headers for the VAR so we can use these when encoding\n",
    "var_names = df.columns[var_indices] \n",
    "\n",
    "# here we create the headers for the exceptions, 0 no exception, 1 is.\n",
    "ex_names = [f'{var_name}_exception' for var_name in var_names] \n",
    "\n",
    "# we zip the lists just to be able to loop over both\n",
    "var_ex_names = list(zip(var_names, ex_names)) \n",
    "\n",
    "# here we encode a violation (exception) as a 1, otherwise 0\n",
    "for var_name, ex_name in var_ex_names:\n",
    "    df[ex_name] = (df[var_name] < df[\"Losses\"]).astype(int) \n",
    "\n",
    "# Get indices of the exception columns (for easy retrieval later)\n",
    "ex_indices = [df.columns.get_loc(ex_name) for ex_name in ex_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3d728d41-dac2-42e4-ab0f-c271528ad3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to actually doing the tests for each year, alpha=0.99 was used in the first exercise for the vars, so we use that here\n",
    "# first create a python dictionary for all the years, so we extract each row (with relevant data) for each year\n",
    "\n",
    "years_data = {}\n",
    "loss_index = [df.columns.get_loc(\"Losses\")]\n",
    "var_ex_loss_indices = var_indices + ex_indices + loss_index\n",
    "\n",
    "for row, year in enumerate(df[\"Year\"]):\n",
    "    data = df.iloc[row, var_ex_loss_indices]\n",
    "    if year in years_data:\n",
    "        years_data[year].append(data)\n",
    "    else:\n",
    "        years_data[year] = [data]\n",
    "\n",
    "# convert each year into a separate dataframe for easy analysis\n",
    "for year in years_data:\n",
    "    years_data[year] = pd.DataFrame(years[year])\n",
    "    \n",
    "#print(years_data[2006])\n",
    "\n",
    "\n",
    "# now we have a python dict with each year with the corresponding losses for that year, and the VARs for those years, exceptions in order aswell inside each year, since we append."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "66df0619-f9cc-4bc0-a6c9-25c34d279f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will actually be doing the tests on each of the VARs\n",
    "# since we only really care about underestimating losses, we will do one sided tests\n",
    "\n",
    "#will be using the binomial distribution from scipy\n",
    "from scipy.stats import binom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c8994470-7190-44ab-92ee-a8317cf40e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function for the kupiec test\n",
    "def kupiec(ex_list: list, alpha=0.99, significance_level=0.05) -> str:\n",
    "    # Total number of observations (days)\n",
    "    n = len(ex_list)\n",
    "    \n",
    "    # Number of violations (exceptions should be 1 for a violation, 0 otherwise)\n",
    "    k = sum(ex_list)\n",
    "    \n",
    "    # The expected probability of a violation under the null hypothesis\n",
    "    p = 1 - alpha\n",
    "\n",
    "    # Handle the case with 0 violations explicitly for clarity\n",
    "    if k == 0:\n",
    "        p_value = 1.0\n",
    "    else:\n",
    "        # For k >= 1, compute the p-value as the probability of seeing at least k violations\n",
    "        p_value = 1 - binom.cdf(k - 1, n, p)\n",
    "    \n",
    "    # Return True if we reject the null hypothesis (p-value is less than the significance level)\n",
    "    test = p_value < significance_level \n",
    "    if test:\n",
    "        return \"Reject\"\n",
    "    else:\n",
    "        return \"Accept\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2a85011d-bc3d-4195-8af5-dace5662c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# function for basel\n",
    "def basel(ex_list: list, alpha = 0.99) -> str:\n",
    "    n = len(ex_list)\n",
    "    p = 1-alpha\n",
    "    k = sum(ex_list)  # Count exceptions\n",
    "\n",
    "    # Compute the cutoffs dynamically\n",
    "    green_yellow = int(binom.ppf(0.95, n, p))  # 95% cutoff\n",
    "    yellow_red = int(binom.ppf(0.99, n, p))  # 99% cutoff\n",
    "\n",
    "    # Assign traffic light zone\n",
    "    if k <= green_yellow:\n",
    "        return \"Green\"\n",
    "    elif green_yellow < k <= yellow_red:\n",
    "        return \"Yellow\"\n",
    "    else:\n",
    "        return \"Red\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b2033-674a-489b-b889-25c53f7f06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for christofferson\n",
    "from scipy.stats import chi2\n",
    "def christofferson(violations: list):\n",
    "\n",
    "    # initialize transition counts\n",
    "    n_00 = n_01 = n_10 = n_11 = 0\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2cb7e91c-7d6f-458b-9f11-b9f6ebbeb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will be performing each of the tests\n",
    "\n",
    "# create a dictionary keeping track of the test results, for each year, on each var (very complicated structure but works wonders)\n",
    "test_data = {\n",
    "    year: \n",
    "               {\n",
    "        var_name:\n",
    "                    {\n",
    "    \"Kupiec\":None, \n",
    "    \"Basel\":None,\n",
    "    \"Christofferson\":None\n",
    "                    }\n",
    "    for var_name in var_names\n",
    "               }\n",
    "    for year in years\n",
    "            }\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e7c6e187-7696-4c82-a1f4-e159e800858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all the years, extract the exception columns, and perform each test on each encoded exception\n",
    "for year, year_dataframe in years_data.items():\n",
    "\n",
    "    #this gives all the exception columns for that year\n",
    "    exceptions_columns = year_dataframe[ex_names] \n",
    "\n",
    "    #var_ex_names is a zipped list with the var and corresponding exceptions column name\n",
    "    for var_name, ex_name in var_ex_names: \n",
    "        \n",
    "        # the violations for that current type of var for that year\n",
    "        ex_list = exceptions_columns[ex_name] \n",
    "\n",
    "         # here we do the kupiec test and store everything for that test, that var, that year\n",
    "        test_data[year][var_name][\"Kupiec\"] = kupiec(ex_list)\n",
    "\n",
    "        # here we do the basel test\n",
    "        test_data[year][var_name][\"Basel\"] = basel(ex_list)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "26a09c17-c1d5-4eea-8588-dacccbb0ba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2006: {'VaRBHS': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}, 'VaREWMA': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}, 'VaRn': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}, 'VaRt': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}, 'VaRPot': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}}, 2007: {'VaRBHS': {'Kupiec': 'Reject', 'Basel': 'Red', 'Christofferson': None}, 'VaREWMA': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}, 'VaRn': {'Kupiec': 'Reject', 'Basel': 'Red', 'Christofferson': None}, 'VaRt': {'Kupiec': 'Reject', 'Basel': 'Red', 'Christofferson': None}, 'VaRPot': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}}, 2008: {'VaRBHS': {'Kupiec': 'Reject', 'Basel': 'Yellow', 'Christofferson': None}, 'VaREWMA': {'Kupiec': 'Reject', 'Basel': 'Yellow', 'Christofferson': None}, 'VaRn': {'Kupiec': 'Reject', 'Basel': 'Red', 'Christofferson': None}, 'VaRt': {'Kupiec': 'Reject', 'Basel': 'Red', 'Christofferson': None}, 'VaRPot': {'Kupiec': 'Accept', 'Basel': 'Green', 'Christofferson': None}}}\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d355fed8-e424-461f-8158-eaeaa2f41444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
